{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) Microsoft Corporation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with Mask RCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First download the model checkpoint from which we will fine tune with our own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-04-18 19:11:15--  http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz\n",
      "Resolving download.tensorflow.org... 172.217.9.176, 2607:f8b0:4000:814::2010\n",
      "Connecting to download.tensorflow.org|172.217.9.176|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 177817887 (170M) [application/x-tar]\n",
      "Saving to: ‘mask_rcnn_inception_v2_coco_2018_01_28.tar.gz’\n",
      "\n",
      "mask_rcnn_inception 100%[===================>] 169.58M   100MB/s    in 1.7s    \n",
      "\n",
      "2019-04-18 19:11:17 (100 MB/s) - ‘mask_rcnn_inception_v2_coco_2018_01_28.tar.gz’ saved [177817887/177817887]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_rcnn_inception_v2_coco_2018_01_28/\n",
      "mask_rcnn_inception_v2_coco_2018_01_28/model.ckpt.index\n",
      "mask_rcnn_inception_v2_coco_2018_01_28/checkpoint\n",
      "mask_rcnn_inception_v2_coco_2018_01_28/pipeline.config\n",
      "mask_rcnn_inception_v2_coco_2018_01_28/model.ckpt.data-00000-of-00001\n",
      "mask_rcnn_inception_v2_coco_2018_01_28/model.ckpt.meta\n",
      "mask_rcnn_inception_v2_coco_2018_01_28/saved_model/\n",
      "mask_rcnn_inception_v2_coco_2018_01_28/saved_model/saved_model.pb\n",
      "mask_rcnn_inception_v2_coco_2018_01_28/saved_model/variables/\n",
      "mask_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb\n"
     ]
    }
   ],
   "source": [
    "!tar -xzvf mask_rcnn_inception_v2_coco_2018_01_28.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir model_maskrcnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will modify the pipeline.config file, let's first copy it to the folder created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./mask_rcnn_inception_v2_coco_2018_01_28/pipeline.config ./model_maskrcnn/stockout_pipeline.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we modify the config file to change number of clases to 1 and make other changes as explained [here.](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/configuring_jobs.md). Let's check the final configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model {\r\n",
      "  faster_rcnn {\r\n",
      "    number_of_stages: 2\r\n",
      "    num_classes: 1\r\n",
      "    image_resizer {\r\n",
      "      keep_aspect_ratio_resizer {\r\n",
      "        min_dimension: 800\r\n",
      "        max_dimension: 1365\r\n",
      "      }\r\n",
      "    }\r\n",
      "    feature_extractor {\r\n",
      "      type: \"faster_rcnn_inception_v2\"\r\n",
      "      first_stage_features_stride: 16\r\n",
      "    }\r\n",
      "    first_stage_anchor_generator {\r\n",
      "      grid_anchor_generator {\r\n",
      "        height_stride: 16\r\n",
      "        width_stride: 16\r\n",
      "        scales: 0.25\r\n",
      "        scales: 0.5\r\n",
      "        scales: 1.0\r\n",
      "        scales: 2.0\r\n",
      "        aspect_ratios: 0.25\r\n",
      "        aspect_ratios: 0.5\r\n",
      "        aspect_ratios: 1.0\r\n",
      "        aspect_ratios: 2.0\r\n",
      "        aspect_ratios: 3.0\r\n",
      "      }\r\n",
      "    }\r\n",
      "    first_stage_box_predictor_conv_hyperparams {\r\n",
      "      op: CONV\r\n",
      "      regularizer {\r\n",
      "        l2_regularizer {\r\n",
      "          weight: 0.0\r\n",
      "        }\r\n",
      "      }\r\n",
      "      initializer {\r\n",
      "        truncated_normal_initializer {\r\n",
      "          stddev: 0.00999999977648\r\n",
      "        }\r\n",
      "      }\r\n",
      "    }\r\n",
      "    first_stage_nms_score_threshold: 0.0\r\n",
      "    first_stage_nms_iou_threshold: 0.6\r\n",
      "    first_stage_max_proposals: 250\r\n",
      "    first_stage_localization_loss_weight: 2.0\r\n",
      "    first_stage_objectness_loss_weight: 1.0\r\n",
      "    initial_crop_size: 14\r\n",
      "    maxpool_kernel_size: 2\r\n",
      "    maxpool_stride: 2\r\n",
      "    second_stage_box_predictor {\r\n",
      "      mask_rcnn_box_predictor {\r\n",
      "        fc_hyperparams {\r\n",
      "          op: FC\r\n",
      "          regularizer {\r\n",
      "            l2_regularizer {\r\n",
      "              weight: 0.0\r\n",
      "            }\r\n",
      "          }\r\n",
      "          initializer {\r\n",
      "            variance_scaling_initializer {\r\n",
      "              factor: 1.0\r\n",
      "              uniform: true\r\n",
      "              mode: FAN_AVG\r\n",
      "            }\r\n",
      "          }\r\n",
      "        }\r\n",
      "        use_dropout: false\r\n",
      "        dropout_keep_probability: 1.0\r\n",
      "        conv_hyperparams {\r\n",
      "          op: CONV\r\n",
      "          regularizer {\r\n",
      "            l2_regularizer {\r\n",
      "              weight: 0.0\r\n",
      "            }\r\n",
      "          }\r\n",
      "          initializer {\r\n",
      "            truncated_normal_initializer {\r\n",
      "              stddev: 0.00999999977648\r\n",
      "            }\r\n",
      "          }\r\n",
      "        }\r\n",
      "        predict_instance_masks: false\r\n",
      "        mask_prediction_conv_depth: 0\r\n",
      "        mask_height: 15\r\n",
      "        mask_width: 15\r\n",
      "        mask_prediction_num_conv_layers: 2\r\n",
      "      }\r\n",
      "    }\r\n",
      "    second_stage_post_processing {\r\n",
      "      batch_non_max_suppression {\r\n",
      "        score_threshold: 0\r\n",
      "        iou_threshold: 0.500000023842\r\n",
      "        max_detections_per_class: 200\r\n",
      "        max_total_detections: 200\r\n",
      "      }\r\n",
      "      score_converter: SOFTMAX\r\n",
      "    }\r\n",
      "    second_stage_localization_loss_weight: 2.0\r\n",
      "    second_stage_classification_loss_weight: 1.0\r\n",
      "    second_stage_mask_prediction_loss_weight: 4.0\r\n",
      "  }\r\n",
      "}\r\n",
      "train_config {\r\n",
      "  batch_size: 1\r\n",
      "  data_augmentation_options {\r\n",
      "    random_horizontal_flip {\r\n",
      "    }\r\n",
      "  }\r\n",
      "  optimizer {\r\n",
      "    momentum_optimizer {\r\n",
      "      learning_rate {\r\n",
      "        manual_step_learning_rate {\r\n",
      "          initial_learning_rate: 0.000199999994948\r\n",
      "          schedule {\r\n",
      "            step: 900000\r\n",
      "            learning_rate: 1.99999994948e-05\r\n",
      "          }\r\n",
      "          schedule {\r\n",
      "            step: 1200000\r\n",
      "            learning_rate: 1.99999999495e-06\r\n",
      "          }\r\n",
      "        }\r\n",
      "      }\r\n",
      "      momentum_optimizer_value: 0.899999976158\r\n",
      "    }\r\n",
      "    use_moving_average: false\r\n",
      "  }\r\n",
      "  gradient_clipping_by_norm: 10.0\r\n",
      "  fine_tune_checkpoint: \"/datadrive/OutOfStockDemo/mask_rcnn_inception_v2_coco_2018_01_28/model.ckpt\"\r\n",
      "  from_detection_checkpoint: true\r\n",
      "  num_steps: 200000\r\n",
      "}\r\n",
      "train_input_reader {\r\n",
      "  label_map_path: \"/datadrive/OutOfStockDemo/stockout_label_map.pbtxt\"\r\n",
      "  load_instance_masks: false\r\n",
      "  tf_record_input_reader {\r\n",
      "    input_path: \"/datadrive/OutOfStockDemo/outputdata/stockout_train.record-?????-of-00002\"\r\n",
      "  }\r\n",
      "}\r\n",
      "eval_config {\r\n",
      "  num_examples: 77\r\n",
      "  max_evals: 10\r\n",
      "  use_moving_averages: false\r\n",
      "}\r\n",
      "eval_input_reader {\r\n",
      "  label_map_path: \"/datadrive/OutOfStockDemo/stockout_label_map.pbtxt\"\r\n",
      "  shuffle: false\r\n",
      "  num_readers: 1\r\n",
      "  tf_record_input_reader {\r\n",
      "    input_path: \"/datadrive/OutOfStockDemo/outputdata/stockout_val.record-?????-of-00001\"\r\n",
      "  }\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!cat ./model_maskrcnn/stockout_pipeline.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to train the model. Since training may take a long time (hours), it is adviced to run the following from a  terminal session that remains active during this time. In the terminal, from ./models/research/ directory, run the following commands.\n",
    "\n",
    "```\n",
    "conda activate outofstock_env\n",
    "```\n",
    "\n",
    "```\n",
    "export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim\n",
    "```\n",
    "\n",
    "```\n",
    "python object_detection/model_main.py --pipeline_config_path=/datadrive/OutOfStockDemo/model_maskrcnn/stockout_pipeline.config --model_dir=/datadrive/OutOfStockDemo/model_maskrcnn/ --num_train_steps=50000  --sample_1_of_n_eval_examples=10 --alsologtostderr\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard can be run using the following command:\n",
    "\n",
    "```\n",
    "tensorboard --logdir=/datadrive/OutOfStockDemo/model_maskrcnn/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow OD API will report the metrics of your model both on tensorboard and your terminal as the training progresses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the training is done or manually interrupted, you can export your model with the following commands to be used for inferance in the next notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir export_maskrcnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From ./models/research/ directory, run the following by replacing the XXXXX with your model checkpoint.\n",
    "\n",
    "```\n",
    "python object_detection/export_inference_graph.py --input_type=image_tensor --pipeline_config_path=/datadrive/OutOfStockDemo/model_maskrcnn/stockout_pipeline.config --trained_checkpoint_prefix=/datadrive/OutOfStockDemo/model_maskrcnn/model.ckpt-XXXXX --output_directory=/datadrive/OutOfStockDemo/export_maskrcnn/\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfod]",
   "language": "python",
   "name": "conda-env-tfod-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, hyperparameter tune with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure Machine Learning allows you to automate hyperparameter exploration in an efficient manner, saving you significant time and resources. You specify the range of hyperparameter values and a maximum number of training runs. The system then automatically launches multiple simultaneous runs with different parameter configurations and finds the configuration that results in the best performance, measured by the metric you choose. Poorly performing training runs are automatically terminated early, reducing the usage of compute resources. These resources are instead used to explore other hyperparameter configurations. For more information, please refer to [how to tune hyperparameters with Azure ML](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters#specify-an-early-termination-policy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import azureml\n",
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.train.dnn import PyTorch\n",
    "from azureml.core.container_registry import ContainerRegistry\n",
    "from azureml.train.hyperdrive import (\n",
    "    RandomParameterSampling,\n",
    "    BanditPolicy,\n",
    "    uniform,\n",
    "    choice,\n",
    "    HyperDriveConfig,\n",
    "    PrimaryMetricGoal,\n",
    ")\n",
    "\n",
    "from dotenv import set_key, get_key, find_dotenv\n",
    "from utilities import get_auth\n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = find_dotenv(raise_error_if_not_found=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first select a name for AMLCompute, number of epochs for training and maximum total runs for hyperdrive. The num epochs and maximum total run parameters deliberately have a low default value for the speed of running. In actual application, set these to higher values (i.e. num_epochs = 10, max_total_runs = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# choose a name for your AMLCompute cluster\n",
    "cluster_name = \"YOUR_CLUSTER_NAME\"\n",
    "\n",
    "# number of epochs\n",
    "num_epochs = 1\n",
    "\n",
    "# max total runs for hyperdrive\n",
    "max_total_runs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_key(env_path, \"cluster_name\", cluster_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config(auth=get_auth(env_path))\n",
    "print(ws.name, ws.resource_group, ws.location, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(workspace=ws, name=\"torchvision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's copy the training script and its dependencies to a script folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_folder = \"./torchdetect\"\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "\n",
    "shutil.copy(\"./scripts/coco_eval.py\", script_folder)\n",
    "shutil.copy(\"./scripts/coco_utils.py\", script_folder)\n",
    "shutil.copy(\"./scripts/engine.py\", script_folder)\n",
    "shutil.copy(\"./scripts/transforms.py\", script_folder)\n",
    "shutil.copy(\"./scripts/utils.py\", script_folder)\n",
    "shutil.copy(\"./scripts/maskrcnn_model.py\", script_folder)\n",
    "shutil.copy(\"./scripts/XMLDataset.py\", script_folder)\n",
    "shutil.copy(\"./scripts/train.py\", script_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload dataset to default datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "ds.container_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.upload(\n",
    "    src_dir=\"./scripts/JPEGImages\",\n",
    "    target_path=\"JPEGImages\",\n",
    "    overwrite=True,\n",
    "    show_progress=True,\n",
    ")\n",
    "ds.upload(\n",
    "    src_dir=\"./scripts/Annotations\",\n",
    "    target_path=\"Annotations\",\n",
    "    overwrite=True,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create  AmlCompute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a compute target for training the model. Here, we create [AmlCompute](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute) as our training compute resource to automate the process of hyperparameter tuning later using this resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print(\"Found existing compute target.\")\n",
    "except ComputeTargetException:\n",
    "    print(\"Creating a new compute target...\")\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=\"STANDARD_NC6\", max_nodes=8\n",
    "    )\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster.\n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create A Pytorch Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first create a pytorch estimator and submit a run to make sure everything works fine before moving on to hyperparamater search. This run can take several hours depending on the num_epochs parameter selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_folder = \"./torchdetect\"\n",
    "image_name = get_key(env_path, \"image_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point to an image in private ACR\n",
    "image_registry_details = ContainerRegistry()\n",
    "image_registry_details.address = get_key(env_path, \"acr_server_name\")\n",
    "image_registry_details.username = get_key(env_path, \"acr_username\")\n",
    "image_registry_details.password = get_key(env_path, \"acr_password\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    \"--data_path\": ds.as_mount(),\n",
    "    \"--workers\": 8,\n",
    "    \"--learning_rate\": 0.005,\n",
    "    \"--epochs\": num_epochs,\n",
    "    \"--anchor_sizes\": \"16,32,64,128,256,512\",\n",
    "    \"--anchor_aspect_ratios\": \"0.25,0.5,1.0,2.0\",\n",
    "    \"--rpn_nms_thresh\": 0.5,\n",
    "    \"--box_nms_thresh\": 0.3,\n",
    "    \"--box_score_thresh\": 0.10,\n",
    "}\n",
    "\n",
    "estimator = PyTorch(\n",
    "    source_directory=script_folder,\n",
    "    script_params=script_params,\n",
    "    compute_target=compute_target,\n",
    "    entry_script=\"train.py\",\n",
    "    use_docker=True,\n",
    "    custom_docker_image=image_name,\n",
    "    image_registry_details=image_registry_details,\n",
    "    user_managed=True,\n",
    "    use_gpu=True,\n",
    ")\n",
    "\n",
    "estimator.run_config.environment.environment_variables[\"PYTHONPATH\"] = \"$PYTHONPATH:/cocoapi/PythonAPI/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = experiment.submit(estimator)\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get more details of your run\n",
    "print(run.get_details())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Model Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we automatically tune hyperparameters by exploring the range of values defined for each hyperparameter. The following run can take several hours depending on number of epochs and number of total runs selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    \"--data_path\": ds.as_mount(),\n",
    "    \"--workers\": 8,\n",
    "    \"--epochs\": num_epochs,\n",
    "    \"--box_nms_thresh\": 0.3,\n",
    "    \"--box_score_thresh\": 0.10,\n",
    "}\n",
    "\n",
    "estimator = PyTorch(\n",
    "    source_directory=script_folder,\n",
    "    script_params=script_params,\n",
    "    compute_target=compute_target,\n",
    "    entry_script=\"train.py\",\n",
    "    use_docker=True,\n",
    "    custom_docker_image=image_name,\n",
    "    image_registry_details=image_registry_details,\n",
    "    user_managed=True,\n",
    "    use_gpu=True,\n",
    ")\n",
    "\n",
    "estimator.run_config.environment.environment_variables[\"PYTHONPATH\"] = \"$PYTHONPATH:/cocoapi/PythonAPI/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use random sampling which randomly selects hyperparameter values from the defined search space. Random sampling allows for both discrete and continuous hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_sampling = RandomParameterSampling(\n",
    "    {\n",
    "        \"learning_rate\": uniform(0.0005, 0.005),\n",
    "        \"rpn_nms_thresh\": uniform(0.3, 0.7),\n",
    "        \"anchor_sizes\": choice(\n",
    "            \"16\",\n",
    "            \"16,32\",\n",
    "            \"16,32,64\",\n",
    "            \"16,32,64,128\",\n",
    "            \"16,32,64,128,256\",\n",
    "            \"16,32,64,128,256,512\",\n",
    "        ),\n",
    "        \"anchor_aspect_ratios\": choice(\n",
    "            \"0.25\", \"0.25,0.5\", \"0.25,0.5,1.0\", \"0.25,0.5,1.0,2.0\"\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will terminate poorly performing runs automatically with bandit early termination policy which is based on slack factor and evaluation interval. The policy terminates any run where the primary metric is not within the specified slack factor with respect to the best performing training run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_termination_policy = BanditPolicy(\n",
    "    slack_factor=0.15, evaluation_interval=2, delay_evaluation=2\n",
    ")\n",
    "\n",
    "hyperdrive_config = HyperDriveConfig(\n",
    "    estimator=estimator,\n",
    "    hyperparameter_sampling=param_sampling,\n",
    "    policy=early_termination_policy,\n",
    "    primary_metric_name=\"mAP@IoU=0.50\",\n",
    "    primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "    max_total_runs=max_total_runs,\n",
    "    max_concurrent_runs=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperdrive_run = experiment.submit(hyperdrive_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunDetails(hyperdrive_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperdrive_run.wait_for_completion(show_output=True, wait_post_processing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and register the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the runs complete, we can find the run that produced the model with the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run.get_details()['runDefinition']['arguments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_run.register_model(model_name = \"torchvision_best_model\", model_path=\"/outputs/model_latest.pth\")\n",
    "print(model.name, model.id, model.version, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can deploy this model using the [deploy deep learning models using Azure ML](https://github.com/microsoft/AKSDeploymentTutorialAML)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now move on to the next notebook to [create an Azure Machine Learning pipeline to run the steps of tuning the hyperparameters and registering the model](05_TrainWithAMLPipeline.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TorchDetectAML]",
   "language": "python",
   "name": "conda-env-TorchDetectAML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

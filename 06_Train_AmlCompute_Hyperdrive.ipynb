{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, hyperparameter tune with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload dataset to default datastore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.0.41\n"
     ]
    }
   ],
   "source": [
    "import azureml\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment = Experiment(workspace=ws, name='torchvision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "script_folder = './torchdetect'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "\n",
    "shutil.copy('coco_eval.py',script_folder)\n",
    "shutil.copy('coco_utils.py',script_folder)\n",
    "shutil.copy('engine.py',script_folder)\n",
    "shutil.copy('transforms.py',script_folder)\n",
    "shutil.copy('utils.py',script_folder)\n",
    "shutil.copy('coco_utils.py',script_folder)\n",
    "shutil.copy('train.py',script_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'azureml-blobstore-a29dc687-5001-4ee4-ac74-7c17b122f449'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.container_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.upload(src_dir='/datadrive/torchvisionOD/BuildData/JPEGImages', target_path='JPEGImages', overwrite=True, show_progress=True)\n",
    "ds.upload(src_dir='/datadrive/torchvisionOD/BuildData/Annotations', target_path='Annotations', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create  AmlCompute¶ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n",
      "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-06-12T18:54:09.191000+00:00', 'errors': None, 'creationTime': '2019-06-11T18:48:22.478352+00:00', 'modifiedTime': '2019-06-11T18:49:10.788499+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"fboyluamlgpuclus\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', \n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create A Pytorch Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_folder = './torchdetect'\n",
    "image_name = 'fboylu/torchdet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "framework_version is not specified, defaulting to version 1.1.\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.dnn import PyTorch\n",
    "\n",
    "script_params = {\n",
    "    '--data_path': ds.as_mount(),\n",
    "    '--workers': 8,\n",
    "    '--learning_rate' : 0.005,\n",
    "    '--epochs' : 5,\n",
    "    '--anchor_sizes' : '16,32,64,128,256,512',\n",
    "    '--anchor_aspect_ratios' : '0.25,0.5,1.0,2.0',\n",
    "    '--rpn_nms_thresh' : 0.5,\n",
    "    '--box_nms_thresh' : 0.3,\n",
    "    '--box_score_thresh' : 0.10    \n",
    "}\n",
    "\n",
    "estimator = PyTorch(source_directory=script_folder, \n",
    "                    script_params=script_params,\n",
    "                    compute_target=compute_target,\n",
    "                    entry_script='train.py',\n",
    "                    use_docker=True,\n",
    "                    custom_docker_image=image_name,\n",
    "                    user_managed=True,\n",
    "                    use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator.run_config.environment.python.interpreter_path = '/data/anaconda/envs/torchdetectaml/bin/python'\n",
    "# estimator.run_config.history.snapshot_project = False\n",
    "estimator.run_config.environment.environment_variables[\"PYTHONPATH\"] = \"$PYTHONPATH:/cocoapi/PythonAPI/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: torchvision,\n",
      "Id: torchvision_1560369221_b26532e3,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Queued)\n"
     ]
    }
   ],
   "source": [
    "run = experiment.submit(estimator)\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'runId': 'torchvision_1560369221_b26532e3', 'target': 'fboyluamlgpuclus', 'status': 'Queued', 'properties': {'azureml.runsource': 'experiment', 'ContentSnapshotId': 'bae6e356-2d31-4b30-bc32-14a0016258b3'}, 'runDefinition': {'script': 'train_str.py', 'arguments': ['--data_path', '$AZUREML_DATAREFERENCE_workspaceblobstore', '--workers', '8', '--learning_rate', '0.005', '--epochs', '5', '--anchor_sizes', '16,32,64,128,256,512', '--anchor_aspect_ratios', '0.25,0.5,1.0,2.0', '--rpn_nms_thresh', '0.5', '--box_nms_thresh', '0.3', '--box_score_thresh', '0.1'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'fboyluamlgpuclus', 'dataReferences': {'workspaceblobstore': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': None, 'pathOnCompute': None, 'overwrite': False}}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment torchvision Environment', 'version': 'Autosave_2019-06-11T18:52:30Z_839b6d6a', 'python': {'interpreterPath': 'python', 'userManagedDependencies': True, 'condaDependencies': {'name': 'project_environment', 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults', 'torch==1.1', 'torchvision==0.2.1', 'horovod==0.16.1']}], 'channels': ['conda-forge']}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE', 'NCCL_SOCKET_IFNAME': 'eth0', 'NCCL_IB_DISABLE': '1', 'NCCL_TREE_THRESHOLD': '0', 'PYTHONPATH': '$PYTHONPATH:/cocoapi/PythonAPI/'}, 'docker': {'baseImage': 'fboylu/torchdet', 'enabled': True, 'sharedVolumes': True, 'gpuSupport': True, 'shmSize': '1g', 'arguments': [], 'baseImageRegistry': {'address': None, 'username': None, 'password': None}}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': False}}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'amlCompute': {'name': None, 'vmSize': None, 'vmPriority': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None}, 'logFiles': {}}\n"
     ]
    }
   ],
   "source": [
    "# to get more details of your run\n",
    "print(run.get_details())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "framework_version is not specified, defaulting to version 1.1.\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.dnn import PyTorch\n",
    "\n",
    "script_params = {\n",
    "    '--data_path': ds.as_mount(),\n",
    "    '--workers': 8,\n",
    "    '--epochs' : 10,\n",
    "    '--box_nms_thresh' : 0.3,\n",
    "    '--box_score_thresh' : 0.10    \n",
    "}\n",
    "\n",
    "estimator = PyTorch(source_directory=script_folder, \n",
    "                    script_params=script_params,\n",
    "                    compute_target=compute_target,\n",
    "                    entry_script='train.py',\n",
    "                    use_docker=True,\n",
    "                    custom_docker_image=image_name,\n",
    "                    user_managed=True,\n",
    "                    use_gpu=True)\n",
    "\n",
    "estimator.run_config.environment.environment_variables[\"PYTHONPATH\"] = \"$PYTHONPATH:/cocoapi/PythonAPI/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, uniform, choice, HyperDriveConfig, PrimaryMetricGoal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_sampling = RandomParameterSampling( {\n",
    "        'learning_rate': uniform(0.0005, 0.005),\n",
    "        'rpn_nms_thresh': uniform(0.3, 0.7),\n",
    "        'anchor_sizes': choice('16', '16,32', '16,32,64', '16,32,64,128', '16,32,64,128,256', '16,32,64,128,256,512'),\n",
    "        'anchor_aspect_ratios': choice('0.25', '0.25,0.5', '0.25,0.5,1.0', '0.25,0.5,1.0,2.0')\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_termination_policy = BanditPolicy(slack_factor=0.15, evaluation_interval=2, delay_evaluation=2)\n",
    "\n",
    "hyperdrive_config = HyperDriveConfig(estimator=estimator,\n",
    "                                     hyperparameter_sampling=param_sampling, \n",
    "                                     policy=early_termination_policy,\n",
    "                                     primary_metric_name='mAP@IoU=0.50',\n",
    "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                     max_total_runs=16,\n",
    "                                     max_concurrent_runs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperdrive_run = experiment.submit(hyperdrive_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bafd7dad04444cbfa78406d225543fd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de14350baa3946f2935167379c009d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(hyperdrive_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: torchvision_1560447191261\n",
      "Web View: https://mlworkspace.azure.ai/portal/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/fboyluamlrg/providers/Microsoft.MachineLearningServices/workspaces/fboyluamlws/experiments/torchvision/runs/torchvision_1560447191261\n",
      "\n",
      "Streaming azureml-logs/hyperdrive.txt\n",
      "=====================================\n",
      "\n",
      "\"<START>[2019-06-13T17:33:11.698316][API][INFO]Experiment created<END>\\n\"\"<START>[2019-06-13T17:33:12.307271][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space<END>\\n\"\"<START>[2019-06-13T17:33:12.471081][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.<END>\\n\"<START>[2019-06-13T17:33:13.7958414Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.<END>\n"
     ]
    }
   ],
   "source": [
    "hyperdrive_run.wait_for_completion(show_output=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torchdetectaml]",
   "language": "python",
   "name": "conda-env-torchdetectaml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, hyperparameter tune with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.0.41\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import azureml\n",
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.train.dnn import PyTorch\n",
    "\n",
    "from dotenv import set_key, get_key, find_dotenv\n",
    "from utilities import get_auth\n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = find_dotenv(raise_error_if_not_found=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fboyluamlws\n",
      "fboyluamlrg\n",
      "eastus\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config(auth=get_auth(env_path))\n",
    "print(ws.name, ws.resource_group, ws.location, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(workspace=ws, name='torchvision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's copy the training script and its dependencies to a script folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./torchdetect/train.py'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_folder = './torchdetect'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "\n",
    "shutil.copy('./scripts/coco_eval.py',script_folder)\n",
    "shutil.copy('./scripts/coco_utils.py',script_folder)\n",
    "shutil.copy('./scripts/engine.py',script_folder)\n",
    "shutil.copy('./scripts/transforms.py',script_folder)\n",
    "shutil.copy('./scripts/utils.py',script_folder)\n",
    "shutil.copy('./scripts/maskrcnn_model.py',script_folder)\n",
    "shutil.copy('./scripts/XMLDataset.py',script_folder)\n",
    "shutil.copy('./scripts/train.py',script_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload dataset to default datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'azureml-blobstore-a29dc687-5001-4ee4-ac74-7c17b122f449'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.container_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.upload(src_dir='./scripts/JPEGImages', target_path='JPEGImages', overwrite=True, show_progress=True)\n",
    "ds.upload(src_dir='./scripts/Annotations', target_path='Annotations', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create  AmlCompute¶ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a compute target for training the model. Here, we create [AmlCompute](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute) as our training compute resource to automate the process of hyperparameter tuning later using this resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a name for your cluster\n",
    "cluster_name = \"YOUR_AMLCOMPUTE_CLUSTER_NAME\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'cluster_name', 'fboyluamlgpuclus')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_key(env_path, \"cluster_name\", cluster_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n",
      "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-06-21T05:35:48.906000+00:00', 'errors': None, 'creationTime': '2019-06-11T18:48:22.478352+00:00', 'modifiedTime': '2019-06-11T18:49:10.788499+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', \n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create A Pytorch Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_folder = './torchdetect'\n",
    "image_name = get_key(env_path, 'image_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.container_registry import ContainerRegistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point to an image in private ACR\n",
    "image_registry_details = ContainerRegistry()\n",
    "image_registry_details.address = get_key(env_path, 'acr_server_name')\n",
    "image_registry_details.username = get_key(env_path, 'acr_username')\n",
    "image_registry_details.password = get_key(env_path, 'acr_password')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "framework_version is not specified, defaulting to version 1.1.\n"
     ]
    }
   ],
   "source": [
    "script_params = {\n",
    "    '--data_path': ds.as_mount(),\n",
    "    '--workers': 8,\n",
    "    '--learning_rate' : 0.005,\n",
    "    '--epochs' : 4,\n",
    "    '--anchor_sizes' : '16,32,64,128,256,512',\n",
    "    '--anchor_aspect_ratios' : '0.25,0.5,1.0,2.0',\n",
    "    '--rpn_nms_thresh' : 0.5,\n",
    "    '--box_nms_thresh' : 0.3,\n",
    "    '--box_score_thresh' : 0.10    \n",
    "}\n",
    "\n",
    "estimator = PyTorch(source_directory=script_folder, \n",
    "                    script_params=script_params,\n",
    "                    compute_target=compute_target,\n",
    "                    entry_script='train.py',\n",
    "                    use_docker=True,\n",
    "                    custom_docker_image=image_name,\n",
    "                    image_registry_details=image_registry_details,\n",
    "                    user_managed=True,\n",
    "                    use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator.run_config.environment.python.interpreter_path = '/data/anaconda/envs/torchdetectaml/bin/python'\n",
    "# estimator.run_config.history.snapshot_project = False\n",
    "estimator.run_config.environment.environment_variables[\"PYTHONPATH\"] = \"$PYTHONPATH:/cocoapi/PythonAPI/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: torchvision,\n",
      "Id: torchvision_1561663460_9a54ec0d,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Starting)\n"
     ]
    }
   ],
   "source": [
    "run = experiment.submit(estimator)\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0918dd422624e3b809115cf368e432b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'runId': 'torchvision_1561663460_9a54ec0d', 'target': 'fboyluamlgpuclus', 'status': 'Queued', 'properties': {'azureml.runsource': 'experiment', 'ContentSnapshotId': '57867cea-1720-41cc-84d1-c22d2d42cf9f', 'azureml.git.repository_uri': 'https://github.com/Microsoft/HyperdriveDeepLearningHappyPathTutorial.git', 'mlflow.source.git.repoURL': 'https://github.com/Microsoft/HyperdriveDeepLearningHappyPathTutorial.git', 'azureml.git.branch': 'fboylu_pytorch', 'mlflow.source.git.branch': 'fboylu_pytorch', 'azureml.git.commit': '955e72ce63186f9a55cfdc34cf40b4e85c31f4a4', 'mlflow.source.git.commit': '955e72ce63186f9a55cfdc34cf40b4e85c31f4a4', 'azureml.git.dirty': 'False'}, 'runDefinition': {'script': 'train.py', 'arguments': ['--data_path', '$AZUREML_DATAREFERENCE_workspaceblobstore', '--workers', '8', '--learning_rate', '0.005', '--epochs', '5', '--anchor_sizes', '16,32,64,128,256,512', '--anchor_aspect_ratios', '0.25,0.5,1.0,2.0', '--rpn_nms_thresh', '0.5', '--box_nms_thresh', '0.3', '--box_score_thresh', '0.1'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'fboyluamlgpuclus', 'dataReferences': {'workspaceblobstore': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': None, 'pathOnCompute': None, 'overwrite': False}}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment torchvision Environment', 'version': 'Autosave_2019-06-27T19:24:22Z_5134ce66', 'python': {'interpreterPath': 'python', 'userManagedDependencies': True, 'condaDependencies': {'name': 'project_environment', 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults', 'torch==1.1', 'torchvision==0.2.1', 'horovod==0.16.1']}], 'channels': ['conda-forge']}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE', 'NCCL_SOCKET_IFNAME': 'eth0', 'NCCL_IB_DISABLE': '1', 'NCCL_TREE_THRESHOLD': '0', 'PYTHONPATH': '$PYTHONPATH:/cocoapi/PythonAPI/'}, 'docker': {'baseImage': 'torchdet', 'baseDockerfile': None, 'enabled': True, 'sharedVolumes': True, 'gpuSupport': True, 'shmSize': '1g', 'arguments': [], 'baseImageRegistry': {'address': 'torchvisionacr.azurecr.io', 'username': 'torchvisionacr', 'password': 'AzureMlSecret=torchvision_1561663460_9a54ec0d#RunConfiguration#ContainerRegistry#Password'}}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': False}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'amlCompute': {'name': None, 'vmSize': None, 'vmPriority': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None}, 'logFiles': {}}\n"
     ]
    }
   ],
   "source": [
    "# to get more details of your run\n",
    "print(run.get_details())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "framework_version is not specified, defaulting to version 1.1.\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.dnn import PyTorch\n",
    "\n",
    "script_params = {\n",
    "    '--data_path': ds.as_mount(),\n",
    "    '--workers': 8,\n",
    "    '--epochs' : 8,\n",
    "    '--box_nms_thresh' : 0.3,\n",
    "    '--box_score_thresh' : 0.10    \n",
    "}\n",
    "\n",
    "estimator = PyTorch(source_directory=script_folder, \n",
    "                    script_params=script_params,\n",
    "                    compute_target=compute_target,\n",
    "                    entry_script='train.py',\n",
    "                    use_docker=True,\n",
    "                    custom_docker_image=image_name,\n",
    "                    image_registry_details=image_registry_details,\n",
    "                    user_managed=True,\n",
    "                    use_gpu=True)\n",
    "\n",
    "estimator.run_config.environment.environment_variables[\"PYTHONPATH\"] = \"$PYTHONPATH:/cocoapi/PythonAPI/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, uniform, choice, HyperDriveConfig, PrimaryMetricGoal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_sampling = RandomParameterSampling( {\n",
    "        'learning_rate': uniform(0.0005, 0.005),\n",
    "        'rpn_nms_thresh': uniform(0.3, 0.7),\n",
    "        'anchor_sizes': choice('16', '16,32', '16,32,64', '16,32,64,128', '16,32,64,128,256', '16,32,64,128,256,512'),\n",
    "        'anchor_aspect_ratios': choice('0.25', '0.25,0.5', '0.25,0.5,1.0', '0.25,0.5,1.0,2.0')\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_total_runs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_termination_policy = BanditPolicy(slack_factor=0.15, evaluation_interval=2, delay_evaluation=2)\n",
    "\n",
    "hyperdrive_config = HyperDriveConfig(estimator=estimator,\n",
    "                                     hyperparameter_sampling=param_sampling, \n",
    "                                     policy=early_termination_policy,\n",
    "                                     primary_metric_name='mAP@IoU=0.50',\n",
    "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                     max_total_runs=max_total_runs,\n",
    "                                     max_concurrent_runs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperdrive_run = experiment.submit(hyperdrive_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7a177f90224ee1a0f8e984d4b2420b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(hyperdrive_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: torchvision_1561667693326\n",
      "Web View: https://mlworkspace.azure.ai/portal/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/fboyluamlrg/providers/Microsoft.MachineLearningServices/workspaces/fboyluamlws/experiments/torchvision/runs/torchvision_1561667693326\n",
      "\n",
      "Streaming azureml-logs/hyperdrive.txt\n",
      "=====================================\n",
      "\n",
      "\"<START>[2019-06-27T20:34:53.810711][API][INFO]Experiment created<END>\\n\"\"<START>[2019-06-27T20:34:54.723016][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space<END>\\n\"\"<START>[2019-06-27T20:34:54.920213][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.<END>\\n\"<START>[2019-06-27T20:34:55.4655731Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.<END>\"<START>[2019-06-27T20:35:24.744216][GENERATOR][INFO]Max number of jobs '4' reached for experiment.<END>\\n\"\"<START>[2019-06-27T20:35:24.971196][GENERATOR][INFO]All jobs generated.<END>\\n\"<START>[2019-06-27T20:35:25.9923132Z][SCHEDULER][INFO]The execution environment was successfully prepared.<END><START>[2019-06-27T20:35:26.0047738Z][SCHEDULER][INFO]Scheduling job, id='torchvision_1561667693326_1'<END><START>[2019-06-27T20:35:26.0073666Z][SCHEDULER][INFO]Scheduling job, id='torchvision_1561667693326_3'<END><START>[2019-06-27T20:35:25.9939310Z][SCHEDULER][INFO]Scheduling job, id='torchvision_1561667693326_0'<END><START>[2019-06-27T20:35:26.0060815Z][SCHEDULER][INFO]Scheduling job, id='torchvision_1561667693326_2'<END><START>[2019-06-27T20:35:27.0075590Z][SCHEDULER][INFO]Successfully scheduled a job. Id='torchvision_1561667693326_0'<END><START>[2019-06-27T20:35:27.1655686Z][SCHEDULER][INFO]Successfully scheduled a job. Id='torchvision_1561667693326_2'<END><START>[2019-06-27T20:35:27.2815983Z][SCHEDULER][INFO]Successfully scheduled a job. Id='torchvision_1561667693326_3'<END><START>[2019-06-27T20:35:27.3638935Z][SCHEDULER][INFO]Successfully scheduled a job. Id='torchvision_1561667693326_1'<END>\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: torchvision_1561667693326\n",
      "Web View: https://mlworkspace.azure.ai/portal/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/fboyluamlrg/providers/Microsoft.MachineLearningServices/workspaces/fboyluamlws/experiments/torchvision/runs/torchvision_1561667693326\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'torchvision_1561667693326',\n",
       " 'target': 'fboyluamlgpuclus',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2019-06-27T20:34:53.644428Z',\n",
       " 'endTimeUtc': '2019-06-27T22:41:44.251618Z',\n",
       " 'properties': {'primary_metric_config': '{\"name\": \"mAP@IoU=0.50\", \"goal\": \"maximize\"}',\n",
       "  'runTemplate': 'HyperDrive',\n",
       "  'azureml.runsource': 'hyperdrive',\n",
       "  'platform': 'AML',\n",
       "  'baggage': 'eyJvaWQiOiAiMDE5MmNhNDMtZTE3OS00NWE2LTg5ZjQtZjQ4YWViZGNjNTIyIiwgInRpZCI6ICI3MmY5ODhiZi04NmYxLTQxYWYtOTFhYi0yZDdjZDAxMWRiNDciLCAidW5hbWUiOiAiMDRiMDc3OTUtOGRkYi00NjFhLWJiZWUtMDJmOWUxYmY3YjQ2In0',\n",
       "  'ContentSnapshotId': '57867cea-1720-41cc-84d1-c22d2d42cf9f'},\n",
       " 'logFiles': {'azureml-logs/hyperdrive.txt': 'https://fboyluamstorage3fdfe5af9.blob.core.windows.net/azureml/ExperimentRun/dcid.torchvision_1561667693326/azureml-logs/hyperdrive.txt?sv=2018-03-28&sr=b&sig=lUZ00Ds1XwBaZNWp65gKZkpScvtwkNFXFZ59pXKmCkA%3D&st=2019-06-27T22%3A31%3A45Z&se=2019-06-28T06%3A41%3A45Z&sp=r'}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperdrive_run.wait_for_completion(show_output=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torchdetectaml]",
   "language": "python",
   "name": "conda-env-torchdetectaml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
